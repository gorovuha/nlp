{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kzf3Qe5WoAb2X7psc5fyTLsnMOm_xd5c",
      "authorship_tag": "ABX9TyPnM59g830d+OUuH9s3d1nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorovuha/nlp/blob/main/collocations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stanza"
      ],
      "metadata": {
        "id": "1wRT_4DSjyMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qDAmuQQyjD-n"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import stanza\n",
        "import pandas as pd\n",
        "from nltk.collocations import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download('ru')\n",
        "nlp = stanza.Pipeline(lang='ru', processors='tokenize, pos, lemma, depparse')"
      ],
      "metadata": {
        "id": "tuLn1_FSjr02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = []\n",
        "\n",
        "f = open('/content/drive/MyDrive/swl.txt', 'r', encoding='utf-8')\n",
        "for item in f:\n",
        "  item = item.replace('\\n', '')\n",
        "  stopwords.append(item)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "-d1eSLOeqQQh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordlist = []\n",
        "\n",
        "f = open('/content/drive/MyDrive/gogol_35.txt', 'r', encoding='utf-8').read()\n",
        "doc = nlp(f)\n",
        "\n",
        "for sent in doc.sentences:\n",
        "  for word in sent.words:\n",
        "    if word.lemma.lower() not in stopwords:\n",
        "      wordlist.append(word.lemma.lower())"
      ],
      "metadata": {
        "id": "iRxWZJGOrfkD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "bigram_finder = BigramCollocationFinder.from_words(wordlist)"
      ],
      "metadata": {
        "id": "C3XYzrsXupIO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "likelihood = []\n",
        "\n",
        "for bigram in bigram_finder.score_ngrams(bigram_measures.likelihood_ratio)[:200]:\n",
        "  likelihood.append([bigram[0][0], bigram[0][1], bigram[1]])\n"
      ],
      "metadata": {
        "id": "kWMHq0kevvxQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(likelihood, columns = ['Target', 'Source', 'Weight'])\n",
        "df1.to_excel('likelihood_bigrams.xlsx', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "Ep_Ucp-twzGn"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}